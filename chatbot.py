import json
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import streamlit as st
import os

# Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙ†Ø§ ÙÙŠ Ø§Ù„ØªØµØ­ÙŠØ­
st.write("ğŸ“‚ Current Working Directory:", os.getcwd())
st.write("ğŸ“„ Files in current directory:", os.listdir())

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„Ù
file_path = "data/medical_knowledge_with_keywords.json"
if not os.path.exists(file_path):
    st.error(f"âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {file_path}")
    st.stop()
else:
    st.success(f"âœ… Ø§Ù„Ù…Ù„Ù Ù…ÙˆØ¬ÙˆØ¯: {file_path}")

# ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
with open(file_path, "r", encoding="utf-8") as f:
    knowledge_base = json.load(f)

# Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙƒÙ„Ù…Ø§Øª
passages = [item["title"] + " " + item.get("summary", "") for item in knowledge_base]
vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(passages)

def find_best_match(question):
    question_vec = vectorizer.transform([question])
    scores = cosine_similarity(question_vec, tfidf_matrix).flatten()
    best_idx = scores.argmax()
    return knowledge_base[best_idx]

# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
st.title("ğŸ¤– Ø§Ù„Ø´Ø§Øª Ø¨ÙˆØª Ø§Ù„Ø·Ø¨ÙŠ")
st.markdown("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ø§Ù„Ø·Ø¨ÙŠ ÙˆØ³ÙŠÙ‚ÙˆÙ… Ø§Ù„Ø¨ÙˆØª Ø¨Ø¥ÙŠØ¬Ø§Ø¯ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ù…Ù† Ø§Ù„ÙƒØªØ¨.")

user_input = st.text_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§...")

if user_input:
    result = find_best_match(user_input)
    if result:
        st.subheader("ğŸ” ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªÙŠØ¬Ø©:")
        st.markdown(f"**Ø§Ù„Ø¹Ù†ÙˆØ§Ù†:** {result['title']}")
        st.markdown(f"**Ø§Ù„Ù…Ù„Ø®Øµ:** {result.get('summary', 'Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ø®Øµ')}")
        st.markdown(f"**Ø§Ù„Ù…ØµØ¯Ø±:** {result.get('category', '-')}")
    else:
        st.warning("Ø¹Ø°Ø±Ù‹Ø§ØŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ØªØ§Ø­Ø© Ù„Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„.")
