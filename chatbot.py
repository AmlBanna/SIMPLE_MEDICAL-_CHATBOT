import json
import re
from sentence_transformers import SentenceTransformer, util
import streamlit as st

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ø³ÙŠØªÙ… ØªÙ†Ø²ÙŠÙ„Ù‡ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø¹Ù†Ø¯ Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø£ÙˆÙ„)
@st.cache_resource
def load_model():
    return SentenceTransformer('all-MiniLM-L6-v2')

model = load_model()

# ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
with open('data/medical_knowledge_with_keywords.json', 'r', encoding='utf-8') as f:
    knowledge_base = json.load(f)

# ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† ÙˆØ§Ù„Ù…Ù„Ø®ØµØ§Øª Ø¥Ù„Ù‰ ØªØ¹Ø¨ÙŠØ±Ø§Øª Ù…Ø¶Ù…Ù†Ø©
passages = [item['title'] + " " + item.get('summary', '') for item in knowledge_base]
embeddings = model.encode(passages, convert_to_tensor=True)

def find_best_match(question):
    question_emb = model.encode(question, convert_to_tensor=True)
    hits = util.semantic_search(question_emb, embeddings, top_k=1)[0]
    best_match = knowledge_base[hits[0]['corpus_id']]
    return best_match

# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
st.title("ğŸ¤– Ø§Ù„Ø´Ø§Øª Ø¨ÙˆØª Ø§Ù„Ø·Ø¨ÙŠ")
st.markdown("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ø§Ù„Ø·Ø¨ÙŠ ÙˆØ³ÙŠÙ‚ÙˆÙ… Ø§Ù„Ø¨ÙˆØª Ø¨Ø¥ÙŠØ¬Ø§Ø¯ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ù…Ù† Ø§Ù„ÙƒØªØ¨.")

user_input = st.text_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§...")

if user_input:
    result = find_best_match(user_input)
    if result:
        st.subheader("ğŸ” ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªÙŠØ¬Ø©:")
        st.markdown(f"**Ø§Ù„Ø¹Ù†ÙˆØ§Ù†:** {result['title']}")
        st.markdown(f"**Ø§Ù„Ù…Ù„Ø®Øµ:** {result.get('summary', 'Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ø®Øµ')}")
        st.markdown(f"**Ø§Ù„Ù…ØµØ¯Ø±:** {result.get('category', '-')}")
    else:
        st.warning("Ø¹Ø°Ø±Ù‹Ø§ØŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ØªØ§Ø­Ø© Ù„Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„.")
